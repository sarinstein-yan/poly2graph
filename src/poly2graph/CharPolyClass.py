import numpy as np
import sympy as sp
import networkx as nx
import tensorflow as tf

from skimage.morphology import skeletonize, dilation, binary_closing, disk
from skimage.util import view_as_blocks

from joblib import Parallel, delayed
from functools import partial
import warnings

from poly2graph.skeleton2graph import skeleton2graph, skeleton2graph_batch
from poly2graph.spectral_graph import (
    PosGoL,
    spectral_potential_batch,
    add_edges_within_threshold,
    contract_close_nodes
)
from poly2graph.hamiltonian import (
    hk2hz_1d, hz2hk_1d,
    expand_hz_as_hop_dict_1d,
    H_1D_batch_from_hop_dict
)
from poly2graph.util import companion_batch, kron_batch, eig_batch, eigvals_batch

from numpy.typing import ArrayLike
from typing import Union, Optional, Callable, Iterable, TypeVar, Set, Dict, Tuple, List, TypeVar
nxGraph = TypeVar('nxGraph', nx.Graph, nx.MultiGraph, nx.DiGraph, nx.MultiDiGraph)


class CharPolyClass:
    def __init__(
        self,
        characteristic: Union[sp.Poly, str, sp.Matrix],
        k: sp.Symbol,
        z: sp.Symbol,
        E: sp.Symbol,
        params: Optional[Set[sp.Symbol]] = {},
        # param_dict: Optional[Dict[sp.Symbol, ArrayLike]] = {},
    ) -> None:
        
        self.k, self.z, self.E = k, z, E
        self.params = sorted(params, key=lambda s: s.name)

        # Initialize based on characteristic type
        if isinstance(characteristic, sp.Poly):
            self.ChP = characteristic
            self._init_from_ChP()
        elif isinstance(characteristic, str):
            param_maps = {k.name: k for k in self.params}
            expr = sp.sympify(characteristic, locals={'z': z, 'E': E, **param_maps})
            assert {E, z}.issubset(expr.free_symbols), (
                f"ChP string must include {E} AND {z} as free symbols"
            )
            self.ChP = sp.Poly(expr, z, 1/z, E)
            self._init_from_ChP()
        elif isinstance(characteristic, sp.Matrix):
            free_sym = characteristic.free_symbols
            if self.k in free_sym and self.z not in free_sym:
                self.h_k = characteristic
                self.h_z = hk2hz_1d(self.h_k, k, z)
            elif self.z in free_sym and self.k not in free_sym:
                self.h_z = characteristic
                self.h_k = hz2hk_1d(self.h_z, k, z)
            else:
                raise ValueError(
                    f"Characteristic matrix must include {k} XOR {z} as a free symbol"
                )
            self._init_from_bloch()
        else:
            raise ValueError("Characteristic must be a sympy Poly, string, or Matrix.")

        self.hop_dict = expand_hz_as_hop_dict_1d(self.h_z, self.z)
        # Prepare coefficients and companion matrix for P(E)(z)
        self._prepare_Poly_z()


    def _init_from_ChP(self) -> None:
        """Initialize attributes when starting from a Characteristic Polynomial."""
        k, z, E = self.k, self.z, self.E
        assert {E, z}.issubset(self.ChP.free_symbols), \
            "ChP must include E and z as free symbols"
        # Generators check, hoppings in both directions should exist
        assert set(self.ChP.gens) == {z, 1/z, E}, \
            f"ChP's generators must be {{z, 1/z, E}}, got {self.ChP.gens}"

        # Treat z as constant and E as variable to find num_bands and h_z
        Poly_E = sp.Poly(self.ChP.as_expr(), E)
        monic_Poly_E = Poly_E.monic()
        self.Poly_E_coeff = Poly_E.all_coeffs()
        self.num_bands = Poly_E.degree()

        # Derive Bloch Hamiltonian h_z (and h_k) from ChP
        if self.num_bands < 1:
            raise ValueError("Characteristic polynomial must be at least one-band.")
        if self.num_bands == 1:
            self.h_z = sp.Matrix([sp.expand(monic_Poly_E.TC())]) # Tailing coefficient
        else:
            self.h_z = sp.Matrix.companion(monic_Poly_E).applyfunc(sp.expand)

        self.h_k = hz2hk_1d(self.h_z, k, z)
        print(f"Derived Bloch Hamiltonian `h_z` with {self.num_bands} bands.")


    def _init_from_bloch(self) -> None:
        """Initialize attributes when starting from a Bloch Hamiltonian Matrix."""
        z, E = self.z, self.E
        
        # Calculate Characteristic polynomial from h_z
        # NOTE: charpoly() creates a new PurePoly object with dummy variables.
        Poly_E_pure = self.h_z.charpoly(E)
        self.Poly_E_coeff = Poly_E_pure.all_coeffs()
        self.num_bands = Poly_E_pure.degree()
        # Replace the dummy variable generated by charpoly with our predefined E
        Poly_E_expr = Poly_E_pure.as_expr().xreplace({Poly_E_pure.gens[0]: E})
        # Define the full ChP including z dependencies
        self.ChP = sp.Poly(Poly_E_expr, z, 1/z, E) # Define gens explicitly
        print(f"Derived Characteristic polynomial `ChP` with {self.num_bands} bands.")


    def _prepare_Poly_z(self) -> None:
        """Prepare coefficients and companion matrix for the polynomial in z."""
        z = self.z
        # Treat E as constant and z as variable
        Poly_z_bigen = sp.Poly(self.ChP.as_expr(), z, 1/z)
        # Right hopping range
        self.poly_p = Poly_z_bigen.degree(1/z)
        # Left hopping range
        self.poly_q = Poly_z_bigen.degree(z)
        Poly_z = sp.Poly(sp.expand(self.ChP.as_expr() * z**self.poly_p), z)
        self.Poly_z_coeff = Poly_z.all_coeffs()
        # Companion matrix of P(E)(z) for efficient root finding
        monic_Poly_z = Poly_z.monic()
        self.companion_E = sp.Matrix.companion(monic_Poly_z).applyfunc(sp.expand)
        # Lambdify coefficients for numerical evaluation later
        self._lambdify_Poly_z_coeffs()


    def _lambdify_Poly_z_coeffs(self):
        """Create lambda functions for evaluating Poly_z coefficients."""
        self.Poly_z_coeff_funcs = []
        allowed_params_set = set(self.params)
        allowed_all_set = allowed_params_set | {self.E}

        for i, expr in enumerate(self.Poly_z_coeff):
            syms = expr.free_symbols
            if not (syms <= allowed_all_set):
                raise ValueError(f"Coefficient {i} contains invalid symbols: {syms - allowed_all_set}")

            if not syms: # Constant
                def eval_const(E_array, param_dict, expr=expr):
                    return np.full_like(E_array, complex(expr), dtype=np.complex128)
                func = eval_const
            
            elif syms == {self.E}: # Depends only on E
                f = sp.lambdify(self.E, expr, modules=["numpy"])
                def eval_E(E_array, param_dict, f=f):
                    return f(E_array)
                func = eval_E
            
            elif syms <= allowed_params_set: # Depends only on params
                f = sp.lambdify(self.params, expr, modules=["numpy"])
                def eval_params(E_array, param_dict, f=f):
                    param_vals = [param_dict[s] for s in self.params]
                    val = f(*param_vals)[..., None, None] # shape: (batch_shape, 1, 1)
                    return np.broadcast_to(val, E_array.shape)
                func = eval_params

            else:  # Depends on E and params
                poly = sp.Poly(expr, self.E)
                # cache {degree: lambdified function} for each monomial coefficient
                monomial_funcs = {}
                for (deg,), coeff_expr in poly.as_dict().items():
                    if coeff_expr.free_symbols:
                        monomial_funcs[deg] = sp.lambdify(self.params, coeff_expr, modules="numpy")
                    else:
                        monomial_funcs[deg] = complex(coeff_expr)

                def eval_params_and_E(E_array, param_dict, monomial_funcs=monomial_funcs):
                    result = np.zeros_like(E_array, dtype=np.complex128)
                    param_vals = [param_dict[s] for s in self.params]
                    for deg, f in monomial_funcs.items():
                        if callable(f):
                            p_val = f(*param_vals)[..., None, None] # shape: (batch_shape, 1, 1)
                        else:
                            p_val = f # already a constant number
                        result += p_val * (E_array ** deg) # shape: E_array.shape
                    return result
                func = eval_params_and_E

            self.Poly_z_coeff_funcs.append(func)
    
    def _get_Poly_z_coeff_arr(self, E_array, param_dict):
        n_coeff = len(self.Poly_z_coeff_funcs)
        target_shape = E_array.shape + (n_coeff,)
        coeff_arr = np.empty(target_shape, dtype=np.complex128)

        for i, func in enumerate(self.Poly_z_coeff_funcs):
            coeff_arr[..., i] = func(E_array, param_dict)

        return coeff_arr
    
    def get_Poly_z_coeff_arr(self, E_array: ArrayLike, param_dict: Dict[sp.Symbol, ArrayLike]):
        E_array, param_dict, batch_shape, num_samples, resolution = \
            self._process_E_array_and_param_dict(E_array, param_dict)
        coeff_arr = self._get_Poly_z_coeff_arr(E_array, param_dict)
        return coeff_arr
    
    def get_Poly_z_roots(
        self,
        E_array: ArrayLike,
        param_dict: Dict[sp.Symbol, ArrayLike],
        device: str = '/CPU:0',
    ):
        coeff_arr = self.get_Poly_z_coeff_arr(E_array, param_dict)
        roots = self._get_Poly_z_roots_from_coeff_arr(coeff_arr, device=device)
        return roots

    def _process_E_array_and_param_dict(self, E_array, param_dict):
        E_array = np.asarray(E_array)
        resolution = E_array.shape[-1]
        param_dict, batch_shape, num_samples = self._process_params_dict(param_dict)
        # NOTE: Disable assertion when generating from safe batches
        assert E_array.shape[:-2] == batch_shape, \
            f"Batch shape of `param_dict` {batch_shape} must match that of `E_array` {E_array.shape[:-2]}."
        return E_array, param_dict, batch_shape, num_samples, resolution

    def _get_Poly_z_roots_from_coeff_arr(
        self,
        coeff_arr: ArrayLike,
        device: str = '/CPU:0',
    ) -> np.ndarray:
        coeff_arr = np.asarray(coeff_arr)
        companion_arr = companion_batch(coeff_arr)
        with tf.device(device):
            companion_tensor = tf.convert_to_tensor(companion_arr)
            roots = tf.linalg.eigvals(companion_tensor)
        return roots.numpy()
    
    def get_spectral_potential_batch(
        self,
        E_array: ArrayLike,
        param_dict: Dict[sp.Symbol, ArrayLike],
        device: str = '/CPU:0',
        method: str = 'ronkin',
    ) -> np.ndarray:
        coeff_arr = self._get_Poly_z_coeff_arr(E_array, param_dict)
        roots = self._get_Poly_z_roots_from_coeff_arr(coeff_arr, device=device)
        phi = spectral_potential_batch(roots, coeff_arr, self.poly_q, method=method)
        return phi

    def _get_Poly_z_coeff(self, E_array, param_vals):
        n_coeff = len(self.Poly_z_coeff)
        target_shape = np.shape(E_array) + (n_coeff,)
        coeff_arr = np.zeros(target_shape, dtype=np.complex128)
        sub_mapping = {s: v for s, v in zip(self.params, param_vals)}

        for i, coeff_expr in enumerate(self.Poly_z_coeff):
            if not coeff_expr.free_symbols:
                coeff_arr[..., i] = complex(coeff_expr)
            else:
                coeff_expr = coeff_expr.subs(sub_mapping)
                coeff_dict = coeff_expr.as_poly(self.E).as_dict()
                for d, c in coeff_dict.items():
                    coeff_arr[..., i] += complex(c) * (E_array ** int(d[0]))
        return coeff_arr
    
    def get_spectral_potential(
        self,
        E_array: ArrayLike,
        param_vals: Iterable, # sorted according to self.params
        device: str = '/CPU:0',
        method: str = 'ronkin',
    ) -> np.ndarray:
        coeff_arr = self._get_Poly_z_coeff(E_array, param_vals)
        roots = self._get_Poly_z_roots_from_coeff_arr(coeff_arr, device=device)
        phi = spectral_potential_batch(roots, coeff_arr, self.poly_q, method=method)
        return phi


    def _process_params_dict(self, param_dict):
        # NOTE: Disable assertions when generating from safe batches
        assert set(param_dict.keys()) == set(self.params), \
            f"param_dict keys {param_dict.keys()} must match params {self.params}."
        param_dict = {s: np.asarray(v) for s, v in param_dict.items()} # Ensure arrays
        # Check if all parameter values have the same shape
        batch_shapes = [v.shape for v in param_dict.values()]
        if not batch_shapes:
            batch_shape = ()
            num_samples = 1
        else:
            assert all(shape == batch_shapes[0] for shape in batch_shapes), \
                "Parameter values must have the same shape."
            batch_shape = batch_shapes[0]
            num_samples = int(np.prod(batch_shape))
        # print(f"Hamiltonian Parameters: {params}; "
        #     f"batch shape {batch_shape}; "
        #     f"{num_samples} total instances.")
        return param_dict, batch_shape, num_samples

    def real_space_H(
        self,
        param_dict: Dict[sp.Symbol, ArrayLike],
        N: int = 40,
        max_dim: int = 150,
        pbc: bool = False,
    ) -> np.ndarray:
        # Limit the size of the real space Hamiltonian to avoid numerical inaccuracies
        if self.num_bands * N > max_dim:
            N = max_dim // self.num_bands
        param_dict = {s: np.asarray(v) for s, v in param_dict.items()}
        H = H_1D_batch_from_hop_dict(self.hop_dict, N, pbc, param_dict)
        return H

    def get_spectral_boundaries(
        self,
        param_dict: Dict[sp.Symbol, ArrayLike],
        device='/CPU:0',
        pad_factor=0.05,
    ) -> None:
        finite_chain = self.real_space_H(param_dict=param_dict)
        E_arr = eigvals_batch(finite_chain, device, is_hermitian=False)
        
        re_min, re_max = np.amin(E_arr.real, axis=-1), np.amax(E_arr.real, axis=-1)
        im_min, im_max = np.amin(E_arr.imag, axis=-1), np.amax(E_arr.imag, axis=-1)
        
        re_center, re_radius = (re_max + re_min) / 2, (re_max - re_min) / 2
        im_center, im_radius = (im_max + im_min) / 2, (im_max - im_min) / 2
        
        radius = np.maximum(re_radius, im_radius) * (1 + pad_factor)
        
        spectral_center = np.stack([re_center, im_center], axis=-1)
        spectral_radius = radius
        spectral_square = np.stack([
            re_center - radius, re_center + radius, 
            im_center - radius, im_center + radius
        ], axis=-1)

        if np.any(radius == 0):
             warnings.warn("Warning: Zero `spectral_radius` detected. "
                    "This may indicate a degenerate spectrum.")

        return spectral_square, spectral_center, spectral_radius

    @staticmethod
    def get_E_array(spectral_square, resolution):
        spectral_square = np.asarray(spectral_square)
        E_real = np.linspace(spectral_square[..., 0], spectral_square[..., 1], 
                             resolution, axis=-1)
        E_imag = np.linspace(spectral_square[..., 2], spectral_square[..., 3], 
                             resolution, axis=-1)
        return E_real[..., None, :] + 1j * E_imag[..., :, None]

    @staticmethod
    def _get_masks(binary, dilation_radius=2):
        mask1 = np.where(binary)
        mask0 = np.where(~binary)
        dilated = dilation(binary, disk(dilation_radius))
        mask1_ = np.where(dilated)
        return mask1, mask0, mask1_
    
    @staticmethod
    def _get_enhanced_threshold(ridge, ridge_block, mask1, mask0, resolution_enhancement):
        weights = np.array([
            ridge_block[mask1].size, 
            ridge[mask0].size * resolution_enhancement**2
        ])
        means = np.array([
            np.mean(ridge_block[mask1]),
            np.mean(ridge[mask0])
        ])
        threshold = np.dot(weights, means) / np.sum(weights)
        return threshold
    
    def _enhance_resolution(self, E_split, param_vals, phi, ridge, binary, device, 
                            resolution_enhancement, method, DOS_filter_kwargs):
        mask1, mask0, mask1_ = CharPolyClass._get_masks(binary)

        E_block = view_as_blocks(E_split, (resolution_enhancement, resolution_enhancement))
        masked_E_block = E_block[mask1_]

        phi_split = self.get_spectral_potential(
            E_array=masked_E_block, param_vals=param_vals,
            device=device, method=method,
        )

        split_kernel = np.ones((resolution_enhancement, resolution_enhancement))
        phi_ = np.kron(phi, split_kernel)
        phi_block = view_as_blocks(phi_, (resolution_enhancement, resolution_enhancement))
        phi_block[mask1_] = phi_split

        ridge_ = PosGoL(phi_, **DOS_filter_kwargs)
        ridge_block = view_as_blocks(ridge_, (resolution_enhancement, resolution_enhancement))
        ridge_block[mask0] = 0

        threshold = self._get_enhanced_threshold(
            ridge, ridge_block, mask1, mask0, resolution_enhancement
        )
        binary_ = ridge_ > threshold
        binary_block = view_as_blocks(binary_, (resolution_enhancement, resolution_enhancement))
        binary_block[mask0] = 0

        return phi_, ridge_, binary_
            
    def _spectral_images_flat(
        self,
        param_dict: Dict[sp.Symbol, Iterable],
        spectral_square: np.ndarray,
        num_samples: int,
        device: str = '/CPU:0',
        batcher_or_n_jobs: Union[Callable, int] = -1,
        resolution: int = 256,
        resolution_enhancement: int = 4,
        method: str = 'ronkin',
        DOS_filter_kwargs: Optional[dict] = {},
    ) -> tuple:
        if isinstance(batcher_or_n_jobs, int):
            batcher = Parallel(n_jobs=batcher_or_n_jobs, prefer='threads')
        else:
            batcher = batcher_or_n_jobs
        
        E_arr = CharPolyClass.get_E_array(spectral_square, resolution)

        phi = self.get_spectral_potential_batch(E_arr, param_dict, device=device, method=method)
        phi_flat = phi.reshape(num_samples, resolution, resolution)

        if method == 'ronkin':
            ridge_list = batcher(
                delayed(partial(PosGoL, **DOS_filter_kwargs))(phi)
                for phi in phi_flat
            )
            ridge_flat = np.array(ridge_list)
        else:
            ridge_flat = phi_flat

        binary_flat = ridge_flat > np.mean(ridge_flat, axis=(-2, -1), keepdims=True)
        
        result = None
        if resolution_enhancement <= 1 or resolution_enhancement is None:
            result = (phi_flat, ridge_flat, binary_flat)
        else: # Apply resolution enhancement
            final_res = resolution * resolution_enhancement
            E_split = CharPolyClass.get_E_array(
                spectral_square.reshape(num_samples, 4), final_res
            )
            param_vals_flat = np.array(
                [param_dict[s].ravel() for s in self.params]
            ).T
            
            result = batcher(
                delayed(self._enhance_resolution)(
                    E_split[i], param_vals_flat[i],
                    phi_flat[i], ridge_flat[i], binary_flat[i], 
                    device, resolution_enhancement, method, DOS_filter_kwargs
                ) for i in range(num_samples)
            )
            result = zip(*result)
        
        return result
    
    def spectral_images(
        self,
        param_dict: Dict[sp.Symbol, ArrayLike],
        n_jobs: Union[Callable, int] = -1,
        device: str = '/CPU:0',
        resolution: int = 256,
        resolution_enhancement: int = 4,
        method: str = 'ronkin',
        DOS_filter_kwargs: Optional[dict] = {},
    ) -> tuple:

        param_dict, batch_shape, num_samples = self._process_params_dict(param_dict)
        
        spectral_square, spectral_center, spectral_radius = \
            self.get_spectral_boundaries(param_dict=param_dict, device=device)
        
        batcher = Parallel(n_jobs=n_jobs, prefer='threads')

        phis, ridges, binaries = self._spectral_images_flat(
            param_dict, spectral_square, num_samples,
            device, batcher, resolution, resolution_enhancement,
            method, DOS_filter_kwargs,
        )

        if len(batch_shape) > 1:
            phis = np.reshape(phis, batch_shape + (resolution, resolution))
            ridges = np.reshape(ridges, batch_shape + (resolution, resolution))
            binaries = np.reshape(binaries, batch_shape + (resolution, resolution))

        return phis, ridges, binaries

    def spectral_graph(
        self,
        param_dict: Dict[sp.Symbol, ArrayLike],
        n_jobs: int = -1,
        device: str = '/CPU:0',
        resolution: int = 256,
        resolution_enhancement: int = 4,
        method: str = 'ronkin',
        short_edge_threshold: Optional[float] = 20,
        skeleton2graph_kwargs: Optional[dict] = {},
        DOS_filter_kwargs: Optional[dict] = {},
        magnify: float = 1.0,
    ) -> nxGraph:
        
        param_dict, batch_shape, num_samples = self._process_params_dict(param_dict)
        
        spectral_square, spectral_center, spectral_radius = \
            self.get_spectral_boundaries(param_dict=param_dict, device=device)
        
        batcher = Parallel(n_jobs=n_jobs, prefer='threads')

        # Get spectral images
        phi_flat, ridge_flat, binary_flat = self._spectral_images_flat(
            param_dict, spectral_square, num_samples,
            device, batcher, resolution, resolution_enhancement,
            method, DOS_filter_kwargs,
        )

        final_res = resolution * resolution_enhancement
        
        graphs = batcher(
            delayed(CharPolyClass._get_skeleton_graph)(
                binary_flat[i], phi_flat[i], ridge_flat[i],
                skeleton2graph_kwargs, short_edge_threshold, 
                spectral_radius[i], spectral_center[i], final_res, magnify
            ) for i in range(num_samples)
        )

        indices = np.arange(num_samples).reshape(batch_shape)

        return graphs, indices
    
    @staticmethod
    def _get_skeleton_graph(binary, phi, ridge, 
                            skeleton2graph_kwargs,
                            short_edge_threshold, 
                            spectral_radius, spectral_center,
                            final_res, magnify):
        # Obtain graph skeleton
        ske = skeletonize(binary, method='lee')
        # Construct skeleton graph
        graph = skeleton2graph(
            ske,
            Potential_image=phi.astype(np.float32),
            DOS_image=ridge.astype(np.float32),
            **skeleton2graph_kwargs
        )
        graph = CharPolyClass._process_skeleton_graph(
            graph, short_edge_threshold,
            spectral_radius, spectral_center,
            final_res, magnify
        )
        return graph

    @staticmethod
    def _process_skeleton_graph(graph, short_edge_threshold, 
                                spectral_radius, spectral_center,
                                final_res, magnify):
        # Merge close nodes and short edges
        if short_edge_threshold is not None and short_edge_threshold > 0:
            graph = add_edges_within_threshold(graph, short_edge_threshold)
            graph = contract_close_nodes(graph, short_edge_threshold)

        # Calculate parameters for coordinate transformation
        scale = spectral_radius * 2 / final_res
        center_offset = np.array([final_res - 1, final_res - 1]) / 2

        # Process graph positions
        graph = CharPolyClass._recover_energy_coordinates(
            graph, spectral_center, scale, center_offset, magnify
        )
        return graph
    
    @staticmethod
    def _recover_energy_coordinates(
        graph: nxGraph, 
        spectral_center: np.ndarray,
        scale: float, 
        center_offset: np.ndarray, 
        magnify: float = 1.0
    ) -> nxGraph:
        if magnify <= 0:
            magnify = 1.0
            
        for node in graph.nodes(data=True):
            if 'pos' in node[1]:
                pos = np.asarray(node[1]['pos'], dtype=np.float32)
                # Recover the (x, y) coordinates from the 2D array indices
                new_pos = (pos[::-1] - center_offset) * scale + spectral_center
                node[1]['pos'] = new_pos * magnify
            if 'pts' in node[1]:
                pts = np.asarray(node[1]['pts'], dtype=np.float32)
                new_pts = (pts[..., ::-1] - center_offset) * scale + spectral_center
                node[1]['pts'] = new_pts * magnify

        for edge in graph.edges(data=True):
            if 'weight' in edge[2]:
                weight = np.asarray(edge[2]['weight'], dtype=np.float32)
                new_weight = weight * scale
                edge[2]['weight'] = new_weight * magnify
            if 'pts' in edge[2]:
                pts = np.asarray(edge[2]['pts'], dtype=np.float32)
                new_pts = (pts[..., ::-1] - center_offset) * scale + spectral_center
                edge[2]['pts'] = new_pts * magnify
                
        return graph